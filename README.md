# Bridging Modal Gaps in Multimodal Sentiment Analysis: A Self-Supervised Text-Guided Fusion Approach

<br/>
## Contributions

●    

## Backgroud and Significance

●    

## The Framework

●   The framework of SETGF. For more details, please wait for the review.

## Usage

### Prerequisites

●    Python ==3.8.18

●    Pytorch==1.13.0

●    CUDA ==12.7

### Datasets and pre-trained berts

Download dataset features and pre-trained berts from the following links.

●   Dataset [Google Cloud Drive](https://drive.google.com/drive/folders/1E5kojBirtd5VbfHsFp6FYWkQunk73Nsv?usp=sharing)

●   Pre-trained berts [BERT](https://github.com/google-research/bert)

For more details, please refer to  [Self-mm](https://github.com/thuiar/Self-MM)

### Run the codes

●   You can first set the training dataset name in run.py as "mosei" , "mosi" or "sims", and then run.

### Results

●   You can view the results in the logs folder.

## Notes

● Please wait for the review to end for more details。
